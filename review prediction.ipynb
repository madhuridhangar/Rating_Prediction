{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points in our data (525814, 10)\n",
      "Filtered data:\n",
      "Number of data points after deduplication:\n",
      "Number of remaining data:\n",
      "After cleaning data:\n",
      "Number of remaining data:\n",
      "(364171, 10)\n",
      "Number of positive and negative reviews :\n",
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the shape of out text BOW vectorizer  (364171, 115281)\n",
      "set of stop words:\n",
      "{'mustn', 'why', 'both', 'd', 'did', 'after', 'yours', 'its', 'ourselves', 'where', 'until', 'isn', 'do', 'were', 'other', 'hadn', \"isn't\", 'each', 'mightn', 'have', 'him', 'his', 'below', \"hadn't\", 'couldn', \"you've\", 'some', 'we', 'aren', \"doesn't\", 'a', 'before', 'and', 'this', 'with', 'doesn', 'ma', 'from', 'in', 'her', 'hers', 'having', 'i', 'not', 'ours', 'down', 'now', 'm', \"shan't\", \"needn't\", 'between', 'themselves', \"aren't\", 'about', 'off', 'is', 'nor', 'there', \"you'd\", 'they', 'during', 'y', \"you'll\", 'should', 'll', 'only', 'our', 'was', 'your', 'wouldn', 've', 'won', 'shouldn', \"didn't\", 'whom', \"mightn't\", 'then', 'shan', 'be', 'who', 'further', 'himself', 'on', 'when', 'he', 'theirs', 'or', 'what', \"don't\", 'all', \"couldn't\", 'the', 'so', 'yourselves', 'into', 'such', 'too', 'those', 'while', 'their', 'for', 'myself', 'through', 'by', 'ain', 'out', 're', \"it's\", \"won't\", 'has', \"should've\", 'which', 't', 'as', \"she's\", 'just', 'at', 'didn', 'weren', 'most', 'being', 'an', 'above', 'my', 'again', \"mustn't\", 'don', 'had', 'if', 'than', 'haven', 's', 'but', 'of', 'wasn', \"you're\", 'am', 'very', 'these', \"hasn't\", 'me', 'once', 'them', \"weren't\", 'o', 'she', 'up', 'against', 'same', 'how', \"that'll\", 'does', \"shouldn't\", 'will', 'more', 'own', 'because', 'under', 'can', 'to', \"wasn't\", 'been', \"haven't\", 'hasn', 'few', 'here', 'yourself', 'that', 'it', 'you', \"wouldn't\", 'itself', 'doing', 'over', 'no', 'are', 'needn', 'any', 'herself'}\n",
      "***********************************************\n",
      "Stemming of word 'tasty'\n",
      "tasti\n",
      "Processed review of CleanedText : \n",
      "Most Common Positive Words :  [(b'like', 137843), (b'tast', 124236), (b'love', 105856), (b'good', 105726), (b'flavor', 104147), (b'use', 102546), (b'great', 96559), (b'one', 92718), (b'product', 84774), (b'tri', 84129), (b'tea', 79284), (b'coffe', 74555), (b'make', 74240), (b'get', 71438), (b'food', 61349), (b'would', 55062), (b'buy', 53035), (b'time', 52441), (b'realli', 52223), (b'eat', 50756)]\n"
     ]
    }
   ],
   "source": [
    "#Given a review, determine whether the review is positive (Rating of 4 or 5) or negative (rating of 1 or 2).\n",
    "#We could use the Score/Rating. A rating of 4 or 5 could be cosnidered a positive review.\n",
    "#A review of 1 or 2 could be considered negative. A review of 3 is nuetral and ignored.\n",
    "#This is an approximate and proxy way of determining the polarity (positivity/negativity) of a review.\n",
    "\n",
    "#loading data\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#1) Reading Data\n",
    "\n",
    "# using the SQLite Table to read data.\n",
    "con = sqlite3.connect('./database.sqlite') \n",
    "\n",
    "#filtering only positive and negative reviews i.e. \n",
    "# not taking into consideration those reviews with Score=3\n",
    "filtered_data = pd.read_sql_query(\"\"\" \n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 \n",
    "\"\"\", con)\n",
    "\n",
    "# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "#changing reviews with score less than 3 to be positive and vice-versa\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "filtered_data['Score'] = positiveNegative\n",
    "\n",
    "#looking at the number of attributes and size of the data\n",
    "print(\"Number of data points in our data\", filtered_data.shape)\n",
    "print(\"Filtered data:\")\n",
    "filtered_data.head()\n",
    "\n",
    "#2) Data Cleaning: (1)Deduplication\n",
    "\n",
    "#Sorting data according to ProductId in ascending order\n",
    "sorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "\n",
    "#Deduplication of entries\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "print(\"Number of data points after deduplication:\")\n",
    "final.shape\n",
    "\n",
    "#Checking to see how much % of data still remains\n",
    "print(\"Number of remaining data:\")\n",
    "(final['Id'].size*1.0)/(filtered_data['Id'].size*1.0)*100\n",
    "\n",
    "# (2)It was also seen that in two rows given below the value of HelpfulnessNumerator is greater than HelpfulnessDenominator \n",
    "#which is not practically possible hence these two rows too are removed from calcualtions\n",
    "\n",
    "display= pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3 AND Id=44737 OR Id=64422\n",
    "ORDER BY ProductID\n",
    "\"\"\", con)\n",
    "print(\"After cleaning data:\")\n",
    "display.head()\n",
    "\n",
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "\n",
    "#Before starting the next phase of preprocessing lets see the number of entries left\n",
    "print(\"Number of remaining data:\")\n",
    "print(final.shape)\n",
    "\n",
    "#How many positive and negative reviews are present in our dataset?\n",
    "print(\"Number of positive and negative reviews :\")\n",
    "final['Score'].value_counts()\n",
    "\n",
    "#3) Featurization:\n",
    "\n",
    "#BAG OF WORDS\n",
    "\n",
    "count_vect = CountVectorizer() #in scikit-learn\n",
    "final_counts = count_vect.fit_transform(final['Text'].values)\n",
    "print(\"the type of count vectorizer \",type(final_counts))\n",
    "print(\"the shape of out text BOW vectorizer \",final_counts.get_shape())\n",
    "\n",
    "#4)Text Preprocessing.\n",
    "stop = set(stopwords.words('english'))#set of stop words\n",
    "sno = nltk.stem.SnowballStemmer('english')#initialising the Snowball Stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, '', sentence)\n",
    "    return cleantext\n",
    "\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[ ? | ! | \\' | \" | # ] ' , r'' , sentence)\n",
    "    cleaned = re.sub(r'[ . | , | ) | ( | \\ | /]' , r'', cleaned)                     \n",
    "    return cleaned\n",
    "print(\"set of stop words:\")\n",
    "print(stop)\n",
    "print(\"***********************************************\")\n",
    "print(\"Stemming of word 'tasty'\")\n",
    "print(sno.stem('tasty'))\n",
    "\n",
    "#code for implementing step-by-step the checks mentioned in pre-processing\n",
    "i = 0\n",
    "str1 = ' '\n",
    "final_string =[]\n",
    "all_positive_words =[] #store words from +ve reviews here\n",
    "all_negative_words =[] #store words from -ve reviews here\n",
    "s = ''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence =[]\n",
    "    #print(sent);\n",
    "    sent = cleanhtml(sent) #remove HTML tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words) > 2)):\n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s = (sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if(final['Score'].values)[i] == 'positive':\n",
    "                        all_positive_words.append(s) #\n",
    "                    if(final['Score'].values)[i] == 'negative': \n",
    "                        all_negative_words.append(s)\n",
    "                else:\n",
    "                    continue\n",
    "                    \n",
    "            else:\n",
    "                continue\n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of clean words\n",
    "    final_string.append(str1)\n",
    "    i += 1\n",
    "#adding a column     \n",
    "final['CleanedText'] = final_string\n",
    "\n",
    "print(\"Processed review of CleanedText : \")\n",
    "final.head()\n",
    "\n",
    "#store final table into an SQlLite table for future use\n",
    "conn = sqlite3.connect('final.sqlite')\n",
    "c = conn.cursor()\n",
    "conn.text_factory = str\n",
    "final.to_sql('Reviews', conn, schema = None, if_exists='replace')\n",
    "\n",
    "freq_dist_positive = nltk.FreqDist(all_positive_words)\n",
    "freq_dist_negative = nltk.FreqDist(all_negative_words)\n",
    "print(\"Most Common Positive Words : \",freq_dist_positive.most_common(20))\n",
    "print(\"Most Common Negative Words : \",freq_dist_negative.most_common(20))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
